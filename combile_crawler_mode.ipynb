{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_url_input( mode):\n",
    "        while True:\n",
    "            fmode = mode.replace('_',' ')\n",
    "            url = input(f'Enter {fmode} URL : ')\n",
    "            if mode == 'single_product':\n",
    "                if ('product' not in url and not re.search(r'https://www\\.digikala\\.com/product/dkp-\\d+/$', url) ):\n",
    "                    print('URL is not belong to any product check it and Please try again.')\n",
    "                    continue\n",
    "            elif mode == 'single_seller':\n",
    "                pattern = re.compile(r'https://www\\.digikala\\.com/seller/[A-Z0-9]+/$')\n",
    "                if  (not pattern.match(url)):\n",
    "                     print(\"URL is not belong to any seller check it and Please try again.\")\n",
    "                     continue\n",
    "            elif mode == 'category':\n",
    "                pattern = re.compile(r'search/\\?q=|/category-|/search/')\n",
    "                if not ('search/?q=' in url or '/category-' in url or '/search/' in url):\n",
    "                    print('Wrong category URL, try one more time')\n",
    "                    continue\n",
    "            break\n",
    "        return url\n",
    "get_url_input( 'single_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scraper_category(self):\n",
    "        while True :\n",
    "            category_url = input(\"enter category url to crawl: \")\n",
    "\n",
    "            if 'search/?q=' in category_url or '/category-' in category_url or '/search/' in category_url:\n",
    "                break\n",
    "            else:\n",
    "                self.log.info('wrong category url, try one more time')       \n",
    "        scroll_count = input(\"Please enter the number of page scroll rates (Example 5 ) : \")\n",
    "        self.get_driver()\n",
    "        try:\n",
    "            scroll_count = int(scroll_count)\n",
    "        except ValueError:\n",
    "            self.log.error(\"The number of scrolling times must be a number. By default, it is set to 3.\")\n",
    "            scroll_count = 3\n",
    "        self.webscraper.check_category(category_url,scroll_count)\n",
    "        self.log.info(\"Data extraction was done successfully.\")\n",
    "\n",
    "def run_scraper_single(self):\n",
    "        seller_page_url = input(\"enter seller page url to crawl: \")\n",
    "        self.get_driver()\n",
    "        self.webscraper.check_seller(seller_page_url)\n",
    "        self.log.info(\"Data extraction was done successfully.\")\n",
    "\n",
    "def run_seller_scraper_product(self):\n",
    "        row_info = self.db_handler.get_row_info(fields=['seller_id', 'seller_name'], table_name='sellers',condition=None,return_as_list=False)\n",
    "        if len(row_info) == 0 :\n",
    "            self.log.warning(\"There are no sellers in the database.\")\n",
    "            return None\n",
    "        \n",
    "        for index, row in enumerate(row_info):\n",
    "            self.log.info(f\"ID {index} : {row[0]}, Name: {row[1]}\")\n",
    "        while True:\n",
    "            try:\n",
    "                user_pick = int(input('choose the seller ID you want to crawl products from: '))\n",
    "                if 0 <= user_pick < len(row_info):\n",
    "                    break\n",
    "                else:\n",
    "                    self.log.info('Invalid choose, please try again.')\n",
    "            except ValueError:\n",
    "                self.log.info('Invalid input, please enter a number.')\n",
    "        selected_seller = row_info[user_pick]\n",
    "        self.get_driver()\n",
    "        self.log.info(f'You chose {selected_seller[1]} with ID {selected_seller[0]}')    \n",
    "        seller_products = self.db_handler.get_row_info(['product_link', 'product_price'], 'products', ['seller_name', selected_seller[1]])\n",
    "        available_products = [product[0] for product in seller_products if product[1] != 'product unavailable']\n",
    "        self.log.info(f'{len(available_products)} available products found for {selected_seller[1]}')\n",
    "        for index, link in enumerate(available_products):\n",
    "            self.log.info(f'Starting to crawl - {index + 1}/{len(available_products)}')\n",
    "            self.product_extraction_scraper.run(link)\n",
    "\n",
    "def run_single_scraper_product(self):\n",
    "        while True:\n",
    "            url = input('Enter product URL: ')\n",
    "            if 'product' not in url:\n",
    "                self.log.info('URL must contain the word \"product\". Please try again.')\n",
    "                continue\n",
    "            if not re.search(r'dkp-\\d+', url):\n",
    "                self.log.info('URL must contain a product ID in the format \"dkp-xxxxxx\". Please try again.')\n",
    "                continue\n",
    "            break        \n",
    "        self.log.info(f'Starting to crawl - {url.split(\"/\")[4]}')\n",
    "        self.get_driver()\n",
    "        self.product_extraction_scraper.run(url)\n",
    "\n",
    "def scraper_all_product_on_db(self,):\n",
    "        seller_products = self.db_handler.get_row_info(['product_link', 'product_price'], 'products')\n",
    "        available_products = [product[0] for product in seller_products if product[1] != 'product unavailable']\n",
    "        self.log.info(f'{len(available_products)} available products found on database ')\n",
    "        for index, link in enumerate(available_products):\n",
    "            self.log.info(f'Starting to crawl - {index + 1}/{len(available_products)}')\n",
    "            self.product_extraction_scraper.run(link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unified_scraper(self, mode):\n",
    "        url = None\n",
    "        if mode in ['single_product', 'single_seller', 'category']:\n",
    "            url = self.get_url_input(mode)\n",
    "        if mode == 'category' : \n",
    "            scroll_count = input(\"Please enter the number of page scroll rates (Example 5 ) : \")\n",
    "            try:\n",
    "                scroll_count = int(scroll_count)\n",
    "            except ValueError:\n",
    "                self.log.error(\"The number of scrolling times must be a number. By default, it is set to 3.\")\n",
    "                scroll_count = 3\n",
    "            \n",
    "        # instalize driver \n",
    "            \n",
    "        if mode == 'all_products':\n",
    "            seller_products = self.db_handler.get_row_info(['product_link', 'product_price'], 'products')\n",
    "            available_products = [product[0] for product in seller_products if product[1] != 'product unavailable']\n",
    "            self.log.info(f'{len(available_products)} available products found on database ')\n",
    "            for index, link in enumerate(available_products):\n",
    "                self.log.info(f'Starting to crawl - {index + 1}/{len(available_products)}')\n",
    "                self.product_extraction_scraper.run(link)\n",
    "                \n",
    "        elif mode == 'single_product':\n",
    "            self.log.info(f'Starting to crawl - {url.split(\"/\")[4]}')\n",
    "            self.product_extraction_scraper.run(url)\n",
    "\n",
    "        elif mode == 'seller_products':\n",
    "            row_info = self.db_handler.get_row_info(fields=['seller_id', 'seller_name'], table_name='sellers',condition=None,return_as_list=False)\n",
    "            if len(row_info) == 0 :\n",
    "                self.log.warning(\"There are no sellers in the database.\")\n",
    "                return None\n",
    "            \n",
    "            for index, row in enumerate(row_info):\n",
    "                self.log.info(f\"ID {index} : {row[0]}, Name: {row[1]}\")\n",
    "            while True:\n",
    "                try:\n",
    "                    user_pick = int(input('choose the seller ID you want to crawl products from: '))\n",
    "                    if 0 <= user_pick < len(row_info):\n",
    "                        break\n",
    "                    else:\n",
    "                        self.log.info('Invalid choose, please try again.')\n",
    "                except ValueError:\n",
    "                    self.log.info('Invalid input, please enter a number.')\n",
    "            \n",
    "            selected_seller = row_info[user_pick]\n",
    "            self.log.info(f'You chose {selected_seller[1]} with ID {selected_seller[0]}')    \n",
    "            seller_products = self.db_handler.get_row_info(['product_link', 'product_price'], 'products', ['seller_name', selected_seller[1]])\n",
    "            available_products = [product[0] for product in seller_products if product[1] != 'product unavailable']\n",
    "            self.log.info(f'{len(available_products)} available products found for {selected_seller[1]}')\n",
    "            for index, link in enumerate(available_products):\n",
    "                self.log.info(f'Starting to crawl - {index + 1}/{len(available_products)}')\n",
    "                self.product_extraction_scraper.run(link)\n",
    "\n",
    "        elif mode == 'single_seller':\n",
    "            self.webscraper.check_seller(url)\n",
    "            self.log.info(\"Data extraction was done successfully.\")\n",
    "            \n",
    "        elif mode == 'category':\n",
    "            self.webscraper.check_category(url,scroll_count)\n",
    "            self.log.info(\"Data extraction was done successfully.\")  \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode selected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
